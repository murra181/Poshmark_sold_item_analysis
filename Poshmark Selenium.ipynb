{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\murra\\anaconda3\\envs\\learn-env\\lib\\site-packages (from selenium) (1.25.10)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import unittest, time, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://poshmark.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(driver, timeout):\n",
    "    scroll_pause_time = timeout\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If heights are the same it will exit the function\n",
    "            break\n",
    "        last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_links(url):\n",
    "    # Setup the driver. This one uses firefox with some options and a path to the geckodriver\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "    # implicitly_wait tells the driver to wait before throwing an exception\n",
    "    driver.implicitly_wait(30)\n",
    "    # driver.get(url) opens the page\n",
    "    driver.get(url)\n",
    "    # This starts the scrolling by passing the driver and a timeout\n",
    "    scroll(driver, 5)\n",
    "    # Once scroll returns bs4 parsers the page_source\n",
    "    soup_a = BeautifulSoup(driver.page_source)\n",
    "    # Them we close the driver as soup_a is storing the page source\n",
    "    driver.close()\n",
    "\n",
    "    # Empty array to store the links\n",
    "    links = []\n",
    "\n",
    "    # Looping through all the a elements in the page source\n",
    "    for link in soup_a.find_all('a'):\n",
    "        # link.get('href') gets the href/url out of the a element\n",
    "        titles = [a.find('a', {'class': 'tile__title tc--b'}).text for a in sold_bags]\n",
    "        brands = [a.find('a', {'class': 'tile__details__pipe__brand ellipses'}).text for a in sold_bags]\n",
    "        links.append(link.get('href'))\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_links(url):\n",
    "    # Setup the driver. This one uses firefox with some options and a path to the geckodriver\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "    # implicitly_wait tells the driver to wait before throwing an exception\n",
    "    driver.implicitly_wait(30)\n",
    "    # driver.get(url) opens the page\n",
    "    driver.get(url)\n",
    "    # This starts the scrolling by passing the driver and a timeout\n",
    "    scroll(driver, 5)\n",
    "    # Once scroll returns bs4 parsers the page_source\n",
    "    soup_a = BeautifulSoup(driver.page_source)\n",
    "    # Them we close the driver as soup_a is storing the page source\n",
    "    driver.close()\n",
    "\n",
    "    # Empty array to store the links\n",
    "\n",
    "    # Looping through all the a elements in the page source\n",
    "\n",
    "        # link.get('href') gets the href/url out of the a element\n",
    "    titles = [a.find('a', {'class': 'tile__title tc--b'}).text for a in soup_a]\n",
    "    brands = [a.find('a', {'class': 'tile__details__pipe__brand ellipses'}).text for a in soup_a]\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['titles','brands'])\n",
    "    df['titles'] = brands\n",
    "    df['brands'] = brands\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>brands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n            kate spade\\n</td>\n",
       "      <td>\\n            kate spade\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 titles                                brands\n",
       "0  \\n            kate spade\\n            \\n            kate spade\\n          "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links('https://poshmark.com/category/Women-Bags?availability=sold_out&condition=nwt_and_ret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
